{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento ML sin balancear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno se exploran los modelos de machine learning a implementar para definir el de mejor ajuste. Se analiza el escenario con el conjunto de datos sin balancear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional, Any\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    accuracy_score, \n",
    "    recall_score\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import(\n",
    "    RandomForestClassifier, HistGradientBoostingClassifier, AdaBoostClassifier\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "home_path = os.path.dirname(os.getcwd())\n",
    "sys.path.append(home_path)\n",
    "\n",
    "source_path = os.path.join(os.path.dirname(os.getcwd()),'src')\n",
    "sys.path.append(source_path)\n",
    "\n",
    "from src.model_management import ClasificadorMora\n",
    "\n",
    "path_etiquetas = os.path.join(home_path, 'data', 'etiquetas.csv')\n",
    "path_info_clientes = os.path.join(home_path, 'data', 'informacion_clientes.csv')\n",
    "path_hist_transacciones = os.path.join(home_path, 'data', 'historial_transacciones.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_threshold(\n",
    "        y_true:np.ndarray, \n",
    "        y_proba:np.ndarray,\n",
    "        metric:Optional[Any]=accuracy_score,\n",
    "        greater_is_better:Optional[bool]=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "    \n",
    "    \"\"\"\n",
    "    Función que permite hallar el threshold óptimo para maximizar una métrica de clasificación.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    y_true:np.ndarray\n",
    "        Arreglo unidimensional con los valores reales de las etiquetas\n",
    "    y_proba:np.ndarray\n",
    "        Arreglo unidimensional con los valores predichos para la probabilidad de la etiqueta 1.\n",
    "    metric:Optional[Any]=accuracy_score\n",
    "        Métrica a optimizar con la selección del threshold\n",
    "    greater_is_better:Optional[bool]=False\n",
    "        Indicador de si la metrica debe maximizarse o minimizarse\n",
    "    \"\"\"\n",
    "\n",
    "    grid = np.arange(0.0,1.01,0.01)\n",
    "\n",
    "    if greater_is_better:\n",
    "        t_index = np.argmax(list(map(\n",
    "            lambda threshold: metric(y_true,np.where(y_proba >= threshold, 1.0, 0.0), **kwargs), grid\n",
    "        )))\n",
    "    else:\n",
    "        t_index = np.argmin(list(map(\n",
    "            lambda threshold: metric(y_true,np.where(y_proba >= threshold, 1.0, 0.0), **kwargs), grid\n",
    "        )))\n",
    "\n",
    "    threshold = grid[t_index]\n",
    "\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_clasificador(y_true:np.ndarray,y_pred:np.ndarray,verbose:Optional[bool]=True):\n",
    "    \"\"\"\n",
    "    Función que arroja métricas y gráficas de evaluación de la clasificación\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    y_true:np.ndarray\n",
    "        Arreglo unidimensional con los valores reales de las etiquetas\n",
    "    y_pred:np.ndarray\n",
    "        Arreglo unidimensional con los valores predichos para la probabilidad de la etiqueta 1.\n",
    "    verbose:bool\n",
    "        Define si deben imprimirse las metricas en pantalla\n",
    "\n",
    "    Results:\n",
    "        (float,float,float)\n",
    "        Valores de las tres métricas\n",
    "    \"\"\"\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Se obtienen las metricas:\\n   - RMSE: {rmse}\\n   - Accuracy: {accuracy}\\n   - recall: {recall}\")\n",
    "    return rmse,accuracy,recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos desbalanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador = ClasificadorMora(\n",
    "    path_etiquetas,\n",
    "    path_info_clientes,\n",
    "    path_hist_transacciones    \n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = clasificador.preprocess()\n",
    "\n",
    "eval_metrics = {\n",
    "    \"rmse\":\"neg_root_mean_squared_error\",\n",
    "    \"accuracy\":\"accuracy\",\n",
    "    \"recall\":\"recall\"\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "150 fits failed out of a total of 400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 55, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got elacsticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [-0.43248019 -0.43284155         nan -0.43740813 -0.43440507 -0.43440507\n",
      "         nan         nan -0.43248019 -0.43284155         nan -0.43320378\n",
      " -0.43283943 -0.43296187         nan         nan -0.43248019 -0.43284155\n",
      "         nan -0.43271779 -0.43248019 -0.43278119         nan         nan\n",
      " -0.43248019 -0.43284155         nan -0.43278119 -0.43248019 -0.43284155\n",
      "         nan         nan -0.43248019 -0.43284155         nan -0.43284155\n",
      " -0.43253853 -0.43284155         nan         nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.81291667 0.81260417        nan 0.80864583 0.81125    0.81125\n",
      "        nan        nan 0.81291667 0.81260417        nan 0.81229167\n",
      " 0.81260417 0.8125            nan        nan 0.81291667 0.81260417\n",
      "        nan 0.81270833 0.81291667 0.81265625        nan        nan\n",
      " 0.81291667 0.81260417        nan 0.81265625 0.81291667 0.81260417\n",
      "        nan        nan 0.81291667 0.81260417        nan 0.81260417\n",
      " 0.81286458 0.81260417        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.24912875 0.24842286        nan 0.2135727  0.23476138 0.23476138\n",
      "        nan        nan 0.24912875 0.24842286        nan 0.24394784\n",
      " 0.24630355 0.24583241        nan        nan 0.24912875 0.24842286\n",
      "        nan 0.24771698 0.24912875 0.24842286        nan        nan\n",
      " 0.24912875 0.24842286        nan 0.24842286 0.24912875 0.24842286\n",
      "        nan        nan 0.24912875 0.24842286        nan 0.24842286\n",
      " 0.24912875 0.24842286        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=&lt;generator object _BaseKFold.split at 0x00000215BD88F510&gt;,\n",
       "             estimator=LogisticRegression(), n_jobs=8,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0],\n",
       "                         &#x27;penalty&#x27;: [&#x27;none&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elacsticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;saga&#x27;]},\n",
       "             refit=&#x27;rmse&#x27;,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;, &#x27;recall&#x27;: &#x27;recall&#x27;,\n",
       "                      &#x27;rmse&#x27;: &#x27;neg_root_mean_squared_error&#x27;},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=&lt;generator object _BaseKFold.split at 0x00000215BD88F510&gt;,\n",
       "             estimator=LogisticRegression(), n_jobs=8,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0],\n",
       "                         &#x27;penalty&#x27;: [&#x27;none&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elacsticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;saga&#x27;]},\n",
       "             refit=&#x27;rmse&#x27;,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;, &#x27;recall&#x27;: &#x27;recall&#x27;,\n",
       "                      &#x27;rmse&#x27;: &#x27;neg_root_mean_squared_error&#x27;},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x00000215BD88F510>,\n",
       "             estimator=LogisticRegression(), n_jobs=8,\n",
       "             param_grid={'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
       "                         'penalty': ['none', 'l1', 'l2', 'elacsticnet'],\n",
       "                         'solver': ['lbfgs', 'saga']},\n",
       "             refit='rmse',\n",
       "             scoring={'accuracy': 'accuracy', 'recall': 'recall',\n",
       "                      'rmse': 'neg_root_mean_squared_error'},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rl_base_model = LogisticRegression()\n",
    "rl_params = {\n",
    "    \"penalty\":['none', \"l1\", \"l2\", \"elacsticnet\"],\n",
    "    \"C\":[0.01,0.1,1.,10.,100.],\n",
    "    \"solver\":[\"lbfgs\",\"saga\"]\n",
    "}\n",
    "rl_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "rl_tunning = GridSearchCV(\n",
    "    estimator=rl_base_model,\n",
    "    param_grid=rl_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=rl_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rl_tunning.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.4200694387042853\n",
      "   - Accuracy: 0.8235416666666666\n",
      "   - recall: 0.36416184971098264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4200694387042853, 0.8235416666666666, 0.36416184971098264)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_parameters = rl_tunning.best_params_\n",
    "\n",
    "rl_model = LogisticRegression(**rl_parameters)\n",
    "rl_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = rl_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "rl_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > rl_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminante cuadrático"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.46502688094345684\n",
      "   - Accuracy: 0.78375\n",
      "   - recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Python\\Environments\\tensorflow_3.9\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46502688094345684, 0.78375, 0.0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_model = QuadraticDiscriminantAnalysis()\n",
    "dc_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = dc_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "dc_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > dc_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=&lt;generator object _BaseKFold.split at 0x000001D09D1D3D60&gt;,\n",
       "             estimator=SVC(), n_jobs=8,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1.0, 10.0],\n",
       "                         &#x27;kernel&#x27;: [&#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             refit=&#x27;rmse&#x27;,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;, &#x27;recall&#x27;: &#x27;recall&#x27;,\n",
       "                      &#x27;rmse&#x27;: &#x27;neg_root_mean_squared_error&#x27;},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=&lt;generator object _BaseKFold.split at 0x000001D09D1D3D60&gt;,\n",
       "             estimator=SVC(), n_jobs=8,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1.0, 10.0],\n",
       "                         &#x27;kernel&#x27;: [&#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             refit=&#x27;rmse&#x27;,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;, &#x27;recall&#x27;: &#x27;recall&#x27;,\n",
       "                      &#x27;rmse&#x27;: &#x27;neg_root_mean_squared_error&#x27;},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=<generator object _BaseKFold.split at 0x000001D09D1D3D60>,\n",
       "             estimator=SVC(), n_jobs=8,\n",
       "             param_grid={'C': [0.01, 0.1, 1.0, 10.0],\n",
       "                         'kernel': ['poly', 'rbf', 'sigmoid']},\n",
       "             refit='rmse',\n",
       "             scoring={'accuracy': 'accuracy', 'recall': 'recall',\n",
       "                      'rmse': 'neg_root_mean_squared_error'},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svm_base_model = SVC()\n",
    "svm_params = {\n",
    "    \"C\":[0.01,0.1,1.,10.],    \n",
    "    \"kernel\":[\"poly\", \"rbf\", \"sigmoid\"]\n",
    "}\n",
    "svm_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "svm_tunning = GridSearchCV(\n",
    "    estimator=svm_base_model,\n",
    "    param_grid=svm_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=svm_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "svm_tunning.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm_parameters = svm_tunning.best_params_\n",
    "svm_parameters_path = os.path.join(source_path,'parameters','svm_parameters.json')\n",
    "with open(svm_parameters_path, 'w') as out_file:\n",
    "    json.dump(svm_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.4170831252080733\n",
      "   - Accuracy: 0.8260416666666667\n",
      "   - recall: 0.3631984585741811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4170831252080733, 0.8260416666666667, 0.3631984585741811)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(random_state=1, probability=True,**svm_parameters)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = svm_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "svm_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > svm_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "knn_base_model = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    \"n_neighbors\":[5,7,9,11,13,15],    \n",
    "    \"weights\":[\"uniform\", \"distance\"],\n",
    "    \"leaf_size\":[10,20,30,50]\n",
    "}\n",
    "knn_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "knn_tunning = GridSearchCV(\n",
    "    estimator=knn_base_model,\n",
    "    param_grid=knn_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=knn_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "knn_tunning.fit(X_train,y_train)\n",
    "\n",
    "knn_parameters = knn_tunning.best_params_\n",
    "\n",
    "knn_parameters = knn_tunning.best_params_\n",
    "knn_parameters_path = os.path.join(source_path,'parameters','knn_parameters.json')\n",
    "with open(knn_parameters_path, 'w') as out_file:\n",
    "    json.dump(knn_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.42866070498705616\n",
      "   - Accuracy: 0.81625\n",
      "   - recall: 0.2610789980732177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.42866070498705616, 0.81625, 0.2610789980732177)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "knn_model = KNeighborsClassifier(**knn_parameters)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = knn_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "knn_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > knn_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "rf_base_model = RandomForestClassifier()\n",
    "rf_params = {\n",
    "    \"criterion\":[\"gini\", \"entropy\", \"log_loss\"],    \n",
    "    \"max_features\":[\"sqrt\", \"log2\"]\n",
    "}\n",
    "rf_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "rf_tunning = GridSearchCV(\n",
    "    estimator=rf_base_model,\n",
    "    param_grid=rf_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=rf_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_tunning.fit(X_train,y_train)\n",
    "\n",
    "rf_parameters = rf_tunning.best_params_\n",
    "\n",
    "rf_parameters = rf_tunning.best_params_\n",
    "rf_parameters_path = os.path.join(source_path,'parameters','rf_parameters.json')\n",
    "with open(rf_parameters_path, 'w') as out_file:\n",
    "    json.dump(rf_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.41907636535600523\n",
      "   - Accuracy: 0.824375\n",
      "   - recall: 0.3786127167630058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.41907636535600523, 0.824375, 0.3786127167630058)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=101,**rf_parameters)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = rf_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "rf_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > rf_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptative boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "ab_base_model = AdaBoostClassifier()\n",
    "ab_params = {\n",
    "    \"learning_rate\":[0.01,0.1,0.2,0.3],    \n",
    "    \"n_estimators\":[10,50,100,250,500,1000]\n",
    "}\n",
    "ab_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "ab_tunning = GridSearchCV(\n",
    "    estimator=ab_base_model,\n",
    "    param_grid=ab_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=ab_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ab_tunning.fit(X_train,y_train)\n",
    "\n",
    "ab_parameters = ab_tunning.best_params_\n",
    "\n",
    "ab_parameters = ab_tunning.best_params_\n",
    "ab_parameters_path = os.path.join(source_path,'parameters','ab_parameters.json')\n",
    "with open(ab_parameters_path, 'w') as out_file:\n",
    "    json.dump(ab_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.4183300132670378\n",
      "   - Accuracy: 0.825\n",
      "   - recall: 0.3092485549132948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4183300132670378, 0.825, 0.3092485549132948)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_model = AdaBoostClassifier(random_state=1,**ab_parameters)\n",
    "ab_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = ab_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "ab_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > ab_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram based Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n"
     ]
    }
   ],
   "source": [
    "hb_base_model = HistGradientBoostingClassifier()\n",
    "hb_params = {\n",
    "    \"learning_rate\":[0.01,0.1,0.2,0.3],    \n",
    "    \"max_iter\":[10,100,200,500,1000],\n",
    "    \"max_leaf_nodes\":[10,20,30,50]\n",
    "}\n",
    "hb_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "hb_tunning = GridSearchCV(\n",
    "    estimator=hb_base_model,\n",
    "    param_grid=hb_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=hb_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "hb_tunning.fit(X_train,y_train)\n",
    "\n",
    "hb_parameters = hb_tunning.best_params_\n",
    "\n",
    "hb_parameters = hb_tunning.best_params_\n",
    "hb_parameters_path = os.path.join(source_path,'parameters','hb_parameters.json')\n",
    "with open(hb_parameters_path, 'w') as out_file:\n",
    "    json.dump(hb_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.41482928215512144\n",
      "   - Accuracy: 0.8279166666666666\n",
      "   - recall: 0.3872832369942196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.41482928215512144, 0.8279166666666666, 0.3872832369942196)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb_model = HistGradientBoostingClassifier(random_state=1,**hb_parameters)\n",
    "hb_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = hb_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "hb_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > hb_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreeme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "xgb_base_model = XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_params = {\n",
    "    \"max_depth\":[3,5,10,15,20],    \n",
    "    \"learning_rate\":[0.01,0.1,0.2],\n",
    "    \"colsample_bytree\":np.arange(0.4,1.0,0.1),\n",
    "    \"colsample_bylevel\":np.arange(0.4,1.0,0.1),\n",
    "    \"subsample\":np.arange(0.5,1.0,0.1),\n",
    "    \"n_estimators\":[100,500]\n",
    "}\n",
    "xgb_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "xgb_tunning = RandomizedSearchCV(\n",
    "    estimator=xgb_base_model,\n",
    "    param_distributions=xgb_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_iter=25,\n",
    "    n_jobs=8,\n",
    "    cv=xgb_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_tunning.fit(X_train,y_train)\n",
    "\n",
    "xgb_parameters = xgb_tunning.best_params_\n",
    "\n",
    "xgb_parameters = xgb_tunning.best_params_\n",
    "xgb_parameters_path = os.path.join(source_path,'parameters','xgb_parameters.json')\n",
    "with open(xgb_parameters_path, 'w') as out_file:\n",
    "    json.dump(xgb_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.4128155358833612\n",
      "   - Accuracy: 0.8295833333333333\n",
      "   - recall: 0.3930635838150289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4128155358833612, 0.8295833333333333, 0.3930635838150289)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(objective=\"binary:logistic\",random_state=1,**xgb_parameters)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = xgb_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "xgb_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > xgb_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_3.9",
   "language": "python",
   "name": "tensorflow_3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
