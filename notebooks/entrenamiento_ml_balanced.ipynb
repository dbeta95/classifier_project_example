{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento ML balanceado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno se exploran los modelos de machine learning a implementar para definir el de mejor ajuste. Se analizan dos escenarios: con el conjunto de dato balanceada con over sampling y con el conjunto de datos balanceado con under sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "home_path = os.path.dirname(os.getcwd())\n",
    "sys.path.append(home_path)\n",
    "\n",
    "source_path = os.path.join(os.path.dirname(os.getcwd()),'src')\n",
    "sys.path.append(source_path)\n",
    "\n",
    "from src.model_management import ClasificadorMora, obtener_threshold, evaluar_clasificador\n",
    "\n",
    "\n",
    "path_etiquetas = os.path.join(home_path, 'data', 'etiquetas.csv')\n",
    "path_info_clientes = os.path.join(home_path, 'data', 'informacion_clientes.csv')\n",
    "path_hist_transacciones = os.path.join(home_path, 'data', 'historial_transacciones.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador = ClasificadorMora(\n",
    "    path_etiquetas,\n",
    "    path_info_clientes,\n",
    "    path_hist_transacciones,\n",
    "    balance_strategy=\"over_sample\" \n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = clasificador.preprocess()\n",
    "\n",
    "eval_metrics = {\n",
    "    \"rmse\":\"neg_root_mean_squared_error\",\n",
    "    \"accuracy\":\"accuracy\",\n",
    "    \"recall\":\"recall\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_os_base_model = SVC()\n",
    "svm_os_params = {\n",
    "    \"C\":[0.01,0.1,1.,10.],    \n",
    "    \"kernel\":[\"poly\", \"rbf\", \"sigmoid\"]\n",
    "}\n",
    "svm_os_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "svm_os_tunning = GridSearchCV(\n",
    "    estimator=svm_os_base_model,\n",
    "    param_grid=svm_os_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=svm_os_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "svm_os_tunning.fit(X_train,y_train)\n",
    "\n",
    "svm_os_parameters = svm_os_tunning.best_params_\n",
    "svm_os_parameters_path = os.path.join(source_path,'parameters','svm_os_parameters.json')\n",
    "with open(svm_os_parameters_path, 'w') as out_file:\n",
    "    json.dump(svm_os_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.42377273783637065\n",
      "   - Accuracy: 0.8204166666666667\n",
      "   - recall: 0.3930635838150289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.42377273783637065, 0.8204166666666667, 0.3930635838150289)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_os_model = SVC(random_state=1, probability=True,**svm_os_parameters)\n",
    "svm_os_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = svm_os_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "svm_os_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > svm_os_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "rf_os_base_model = RandomForestClassifier()\n",
    "rf_os_params = {\n",
    "    \"criterion\":[\"gini\", \"entropy\", \"log_loss\"],    \n",
    "    \"max_features\":[\"sqrt\", \"log2\"],\n",
    "    \"n_estimators\":[100,200]\n",
    "}\n",
    "rf_os_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "rf_os_tunning = GridSearchCV(\n",
    "    estimator=rf_os_base_model,\n",
    "    param_grid=rf_os_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=rf_os_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_os_tunning.fit(X_train,y_train)\n",
    "\n",
    "rf_os_parameters = rf_os_tunning.best_params_\n",
    "\n",
    "rf_os_parameters = rf_os_tunning.best_params_\n",
    "rf_os_parameters_path = os.path.join(source_path,'parameters','rf_os_parameters.json')\n",
    "with open(rf_os_parameters_path, 'w') as out_file:\n",
    "    json.dump(rf_os_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.42841763113423176\n",
      "   - Accuracy: 0.8164583333333333\n",
      "   - recall: 0.31888246628131023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.42841763113423176, 0.8164583333333333, 0.31888246628131023)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_os_model = RandomForestClassifier(random_state=1,**rf_os_parameters)\n",
    "rf_os_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = rf_os_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "rf_os_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > rf_os_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram based boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n"
     ]
    }
   ],
   "source": [
    "hb_os_base_model = HistGradientBoostingClassifier()\n",
    "hb_os_params = {\n",
    "    \"learning_rate\":[0.01,0.1,0.2,0.3],    \n",
    "    \"max_iter\":[10,100,200,500,1000],\n",
    "    \"max_leaf_nodes\":[10,20,30,50]\n",
    "}\n",
    "hb_os_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "hb_os_tunning = GridSearchCV(\n",
    "    estimator=hb_os_base_model,\n",
    "    param_grid=hb_os_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=hb_os_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "hb_os_tunning.fit(X_train,y_train)\n",
    "\n",
    "hb_os_parameters = hb_os_tunning.best_params_\n",
    "\n",
    "hb_os_parameters = hb_os_tunning.best_params_\n",
    "hb_os_parameters_path = os.path.join(source_path,'parameters','hb_os_parameters.json')\n",
    "with open(hb_os_parameters_path, 'w') as out_file:\n",
    "    json.dump(hb_os_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.4235268586524354\n",
      "   - Accuracy: 0.820625\n",
      "   - recall: 0.29190751445086704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4235268586524354, 0.820625, 0.29190751445086704)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb_os_model = HistGradientBoostingClassifier(random_state=1,**hb_os_parameters)\n",
    "hb_os_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = hb_os_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "hb_os_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > hb_os_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "xgb_os_base_model = XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_os_params = {\n",
    "    \"max_depth\":[3,5,10,15,20],    \n",
    "    \"learning_rate\":[0.01,0.1,0.2],\n",
    "    \"colsample_bytree\":np.arange(0.4,1.0,0.1),\n",
    "    \"colsample_bylevel\":np.arange(0.4,1.0,0.1),\n",
    "    \"subsample\":np.arange(0.5,1.0,0.1),\n",
    "    \"n_estimators\":[100,500]\n",
    "}\n",
    "xgb_os_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "xgb_os_tunning = RandomizedSearchCV(\n",
    "    estimator=xgb_os_base_model,\n",
    "    param_distributions=xgb_os_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_iter=25,\n",
    "    n_jobs=8,\n",
    "    cv=xgb_os_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_os_tunning.fit(X_train,y_train)\n",
    "\n",
    "xgb_os_parameters = xgb_os_tunning.best_params_\n",
    "\n",
    "xgb_os_parameters = xgb_os_tunning.best_params_\n",
    "xgb_os_parameters_path = os.path.join(source_path,'parameters','xgb_os_parameters.json')\n",
    "with open(xgb_os_parameters_path, 'w') as out_file:\n",
    "    json.dump(xgb_os_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.4306003560921271\n",
      "   - Accuracy: 0.8145833333333333\n",
      "   - recall: 0.2861271676300578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4306003560921271, 0.8145833333333333, 0.2861271676300578)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_os_model = XGBClassifier(objective=\"binary:logistic\",random_state=1,**xgb_os_parameters)\n",
    "xgb_os_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = xgb_os_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "xgb_os_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > xgb_os_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador = ClasificadorMora(\n",
    "    path_etiquetas,\n",
    "    path_info_clientes,\n",
    "    path_hist_transacciones,\n",
    "    balance_strategy=\"under_sample\" \n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = clasificador.preprocess()\n",
    "\n",
    "eval_metrics = {\n",
    "    \"rmse\":\"neg_root_mean_squared_error\",\n",
    "    \"accuracy\":\"accuracy\",\n",
    "    \"recall\":\"recall\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "rf_us_base_model = RandomForestClassifier()\n",
    "rf_us_params = {\n",
    "    \"criterion\":[\"gini\", \"entropy\", \"log_loss\"],    \n",
    "    \"max_features\":[\"sqrt\", \"log2\"],\n",
    "    \"n_estimators\":[100,200,1000]\n",
    "}\n",
    "rf_us_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "rf_us_tunning = GridSearchCV(\n",
    "    estimator=rf_us_base_model,\n",
    "    param_grid=rf_us_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=rf_us_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_us_tunning.fit(X_train,y_train)\n",
    "\n",
    "rf_us_parameters = rf_us_tunning.best_params_\n",
    "\n",
    "rf_us_parameters = rf_us_tunning.best_params_\n",
    "rf_us_parameters_path = os.path.join(source_path,'parameters','rf_us_parameters.json')\n",
    "with open(rf_us_parameters_path, 'w') as out_file:\n",
    "    json.dump(rf_us_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.42180169116145877\n",
      "   - Accuracy: 0.8220833333333334\n",
      "   - recall: 0.35452793834296725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.42180169116145877, 0.8220833333333334, 0.35452793834296725)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_us_model = RandomForestClassifier(random_state=1,**rf_us_parameters)\n",
    "rf_us_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = rf_us_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "rf_us_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > rf_us_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram based boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n"
     ]
    }
   ],
   "source": [
    "hb_us_base_model = HistGradientBoostingClassifier()\n",
    "hb_us_params = {\n",
    "    \"learning_rate\":[0.01,0.1,0.2,0.3],    \n",
    "    \"max_iter\":[10,100,200,500,1000],\n",
    "    \"max_leaf_nodes\":[10,20,30,50]\n",
    "}\n",
    "hb_us_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "hb_us_tunning = GridSearchCV(\n",
    "    estimator=hb_us_base_model,\n",
    "    param_grid=hb_us_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_jobs=8,\n",
    "    cv=hb_us_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "hb_us_tunning.fit(X_train,y_train)\n",
    "\n",
    "hb_us_parameters = hb_us_tunning.best_params_\n",
    "\n",
    "hb_us_parameters = hb_us_tunning.best_params_\n",
    "hb_us_parameters_path = os.path.join(source_path,'parameters','hb_us_parameters.json')\n",
    "with open(hb_us_parameters_path, 'w') as out_file:\n",
    "    json.dump(hb_us_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.4173328008516305\n",
      "   - Accuracy: 0.8258333333333333\n",
      "   - recall: 0.37957610789980734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4173328008516305, 0.8258333333333333, 0.37957610789980734)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb_us_model = HistGradientBoostingClassifier(random_state=1,**hb_us_parameters)\n",
    "hb_us_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = hb_us_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "hb_us_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > hb_us_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "xgb_us_base_model = XGBClassifier(objective=\"binary:logistic\")\n",
    "xgb_us_params = {\n",
    "    \"max_depth\":[3,5,10,15,20],    \n",
    "    \"learning_rate\":[0.01,0.1,0.2],\n",
    "    \"colsample_bytree\":np.arange(0.4,1.0,0.1),\n",
    "    \"colsample_bylevel\":np.arange(0.4,1.0,0.1),\n",
    "    \"subsample\":np.arange(0.5,1.0,0.1),\n",
    "    \"n_estimators\":[100,500]\n",
    "}\n",
    "xgb_us_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "xgb_us_tunning = RandomizedSearchCV(\n",
    "    estimator=xgb_us_base_model,\n",
    "    param_distributions=xgb_us_params,\n",
    "    scoring=eval_metrics,\n",
    "    n_iter=25,\n",
    "    n_jobs=8,\n",
    "    cv=xgb_us_skf.split(X_train,y_train),\n",
    "    refit=\"rmse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_us_tunning.fit(X_train,y_train)\n",
    "\n",
    "xgb_us_parameters = xgb_us_tunning.best_params_\n",
    "\n",
    "xgb_us_parameters = xgb_us_tunning.best_params_\n",
    "xgb_us_parameters_path = os.path.join(source_path,'parameters','xgb_us_parameters.json')\n",
    "with open(xgb_us_parameters_path, 'w') as out_file:\n",
    "    json.dump(xgb_us_parameters, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtienen las metricas:\n",
      "   - RMSE: 0.4143267631552018\n",
      "   - Accuracy: 0.8283333333333334\n",
      "   - recall: 0.3805394990366089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4143267631552018, 0.8283333333333334, 0.3805394990366089)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_us_model = XGBClassifier(objective=\"binary:logistic\",random_state=1,**xgb_us_parameters)\n",
    "xgb_us_model.fit(X_train, y_train)\n",
    "\n",
    "y_proba = xgb_us_model.predict_proba(X_test)[:,1].reshape(-1,)\n",
    "xgb_us_threshold = obtener_threshold(y_test, y_proba,mean_squared_error, greater_is_better=False,**{\"squared\":False})\n",
    "\n",
    "y_pred = np.where(y_proba > xgb_us_threshold, 1., 0.)\n",
    "evaluar_clasificador(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_3.9",
   "language": "python",
   "name": "tensorflow_3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
